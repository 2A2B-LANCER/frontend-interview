## HTTP

------

### HTTP常见面试题

------

#### HTTP基本概念

------

超文本传输协议

> HTTP 是一个在计算机中专门在 **两端** 之间传输 文本、图片、音频、视频等 **超文本** 数据的 **约定和规范**

主要从三方面来理解

1. 超文本：字面意思，就是能够传输的数据不只有文本，现在文本的含义已经可以扩展为图片、视频、压缩包等了，**超的关键是超链接**，用于从一个超文本跳转到另一个超文本
2. 传输：端对端进行数据搬运，两个特点：双向，可中转
3. 协议：某个行为的两个以上的参与者用来制约大家行为的约定和规范



#### HTTP常见状态码

------

|      | 具体含义                                           | 常见状态码      |
| ---- | -------------------------------------------------- | --------------- |
| 1xx  | 提示信息，表示目前处于协议处理的中间状态           |                 |
| 2xx  | 成功，已经收到报文并被正确处理                     | 200/204/206     |
| 3xx  | 重定向，资源位置发生变动，需要重新向服务器发起请求 | 301/302/304     |
| 4xx  | 客户端错误，请求报文出错                           | 400/403/404     |
| 5xx  | 服务端错误，服务器在处理请求时内部出错             | 500/501/502/503 |

- `2xx` 成功
- `200 OK`：一切正常，除了 `HEAD` 请求，都会有 `body` 数据
- `204 No Content`：与 200 基本相同，没有 `body` 数据
- `206 Partial Content`：HTTP分块下载或断点续传，表明当前返回的 `body` 数据不是资源的全部
- `3xx` 重定向
- `301 Moved Permanently`：永久重定向
- `302 Found`：临时重定向，301和302都会在响应头里使用字段 `Location`，指明后续要跳转的 URL
- `304 Not Modified`：协商缓存命中，这代表服务器端数据没有更新，浏览器直接使用缓存中的数据
- `4xx` 客户端发送的报文有误
- `400 Bad Request`：客户端请求的报文有错误
- `403 Forbidden`：服务器禁止访问资源，请求没错
- `404 Not Found`：请求的资源在服务器未找到
- `5xx` 服务器处理请求时内部出错
- `500 Internal Server Error`：服务器出错
- `501 Not Implemented`：客户端请求的功能还未实现
- `502 Bad Gateway`：通常是服务器作为⽹关或代理时返回的错误码，表示服务器⾃身⼯作正常，访问后端服务器 发⽣了错误
- `503 Service Unavailable`：服务器繁忙



#### HTTP 常见字段

| 字段名           | 作用                                                         |
| ---------------- | ------------------------------------------------------------ |
| Host             | 指定服务器的域名                                             |
| Content-length   | 本次相应的数据长度                                           |
| Connection       | 常⽤于客户端要求服务器使⽤ TCP 持久连接(keep-alive)，直到客户端或服务器主动关闭连接 |
| Content-Type     | ⽤于服务器回应时，告诉客户端，本次数据是什么格式             |
| Accept           | 客户端请求的时候，⽤以声明⾃⼰可以接受哪些数据格式           |
| Content-Encoding | 表示服务器返回的数据使⽤了什么压缩格式                       |
| Accept-Encoding  | 客户端在请求时，⽤以说明⾃⼰可以接受哪些压缩⽅法             |



#### GET 与 POST 的区别？

GET 方法用于从服务器获取资源

POST 方法用于对服务器的资源进行修改



#### GET 和 POST 方法 是 安全和幂等的吗？

> 安全：在 HTTP 协议中，是指请求方法不会 **破坏** 服务器上的资源

> 幂等：多次 **执行相同的操作**，**结果都是相同的**

- GET
  - 因为 GET 方法是 **只读** 操作，所以肯定 **是安全的**
  - 一般意义上来讲，GET 方法 **是幂等的**，因为 GET方法是用来从服务器获取资源的只读操作，它不应该改变服务器上的资源
- POST
  - POST 方法是 **新增或提交数据的** 操作，会修改服务器上的资源，所以 **不是安全的**
  - 每一次提交都会修改服务器上的资源，所以执行相同的操作，结果也不同，**不是幂等的**



#### HTTP/1.1 的优点有哪些，怎么体现的？

1. 简单：HTTP 基本的报文格式是 `header + body`，头部信息也是 `key-value`形式的简单文本，易于学习
2. 灵活和易于扩展：请求方法多种多样；URL/URI 除了少数几个参数是固定的，大部分是自定义的；状态码除了常用的还可以自己定义；头部信息也是可以自定义；等等，HTTP协议中很多都允许开发人员 **自定义和扩充**；HTTP 位于 应用层，下层可以随意变化；比如 HTTPS 就是在 HTTP 和 TCP 之间建立了 SSL/TLS 安全传输层；HTTP3 甚至把 TCP 换成了基于 UDP 的 QUIC
3. 应用广泛和跨平台：各种用户端都在使用，天然跨平台

#### HTTP/1.1  的缺点有哪些？

- 无状态
  - 好处：不需要额外的资源记录状态信息，减轻服务器压力
  - 坏处：服务器没有记忆，在完成有关联性的操作的时候会非常麻烦；
  - 坏处的解决方案之一：Cookie，通过在请求和响应报文中写入 Cookie 来控制客户端的状态
- 明文传输
  - 好处：方便阅读，浏览器的 F12 控制台或 Wireshark 抓包都可以直接查看
  - 坏处：HTTP 的所有信息都是暴露下的，多阶段的传输可能会导致信息泄露
- 不安全（**缺点**）
  - 明文传输，信息可能会泄露
  - 不验证通信方的身份，可能遭遇伪装
  - 无法验证报文的完整性，有可能已经被篡改了

**安全问题如何解决？**

HTTPS，通过引入 SSL/TLS 安全传输层来解决

#### HTTP/1.1 的性能如何？

HTTP 协议基于 **TCP/IP**，使用 **请求-应答** 的通信模式

- 长连接（TCP 持久连接）

一般的 HTTP 请求（短连接），是**每发起一次请求都要进行一次 TCP 连接（三次握手），而且是串行请求**，这无疑会增加通信开销

长连接就是解决这个问题的，它有效的**减少 TCP 连接的重复建立和断开造成的额外开销**，减轻了服务器端的压力

特点是：**只要任意一端没有明确断开连接，就保持 TCP 连接的状态**

- 管道网络传输

长连接使得管道网络传输成为了可能

短连接是这样的：

1. TCP 建立连接
2. 请求A发送
3. 请求A响应
4. TCP 断开连接
5. TCP 建立连接
6. 请求B发送
7. 请求B响应
8. TCP 断开连接

B请求发送之前必须等 A 请求完成响应，并且断开TCP连接，然后重连

长连接的普通形式：

1. TCP 建立连接
2. 请求A发送
3. 请求A响应
4. 请求B发送
5. 请求B响应
6. TCP 断开连接

这样的 长连接 解决的问题是 TCP 断开重连的性能额外开销，但是，**请求B的发送仍旧需要等待 请求A 的响应完成**

**管道机制**

1. TCP 建立连接
2. 请求A发送
3. 请求B发送
4. 请求A响应
5. 请求B响应
6. TCP 断开连接

请求 A 和 请求 B 可以同时发送，**但是响应依旧是按照请求发送顺序的**

要是前⾯的回应特别慢，后⾯就会有许多请求排队等着。这称为 **队头堵塞**。

- 队头阻塞

**请求 - 应答** 的模式加剧了 HTTP 的性能问题。 因为当顺序发送的请求序列中的⼀个请求因为某种原因被阻塞时，在后⾯排队的所有请求也⼀同被阻塞了，会招致 客户端⼀直请求不到数据，这也就是 **队头阻塞**。好⽐上班的路上塞⻋



#### HTTP 与 HTTPS 的区别？

1. HTTP 是明文传输，有安全风险，HTTPS 在 HTTP 和 TCP 之间加入了 SSL/TLS 安全协议，使得报文能够加密传输
2. HTTP 连接建立相对简单，TCP 三次握手之后就可以进行 HTTP 的报文传输；HTTPS 在 TCP 三次握手之后，还需要进行 SSL/TLS 的握手过程，才能进行加密报文的传输
3. HTTP 的端口号是 80；HTTPS 的端口号是 443
4. HTTPS 协议需要向 证书权威机构（CA）申请数字证书，来保证服务器的身份是可信的



#### HTTPS 解决了 HTTP 的哪些问题？

1. 窃听风险：因为是明文传输而导致的
2. 篡改风险：因为无法验证报文完整性（也是因为明文传输）
3. 冒充风险：无法验证通信方身份

加入 SSL/TLS 协议之后，解决了以上问题：

1. 信息加密：窃听到信息之后，也没办法解密
2. 校验机制：通信内容篡改之后就无法正常显示
3. 身份验证：解决冒充问题



#### HTTPS 是如何解决 HTTP 的问题的？

1. **混合加密** 实现信息的 **机密性**，解决窃听问题

> 混合加密就是结合使用 对称加密 和 非对称加密

- 在通信建立前采用 **非对称加密** 的方式交换 **会话秘钥**
- 通信过程中使用 **对称加密** 的方式进行加/解密明文数据

为什么采用混合加密？

- 对称加密使用一个秘钥，**运算速度快**，但是 **无法做到安全的密钥交换**
- 非对称加密使用 公钥和私钥，**解决了密钥交换问题但是速度慢**

2. **摘要算法** 实现数据的 **完整性**，防止数据被篡改

客户端发送的加密数据包含两部分：明文 和 摘要

服务端解密后，用相同的摘要算法计算获得的明文，再把结果和接收的摘要进行比较，如果相同则说明数据完整

3. 把服务器公钥放入到 **数字证书**，解决冒充风险

数字证书包含 **服务器公钥 和 CA 数字签名**

客户端通过 CA的公钥检验数字证书的真实性，如果是真实的（说明通信方的身份是有效的），就使用 数字证书中的服务器公钥加密报文，这样就解决了冒充的风险



#### HTTPS 是如何建立连接的？SSL/TLS1.2 四次握手阶段交互了什么？

SSL/TLS 协议基本流程：

- 客户端向服务器索要并验证服务器的公钥
- 双方协商生成 **会话秘钥**
- 双方使用会话秘钥进行加密通信

前两步就是 SSL/TLS 的建立过程（握手阶段）

SSL/TLS 的握手阶段涉及四次通信

1. Client Hello

   由客户端向服务器发起加密通信请求，也就是 `Client Hello` 请求

   主要包含以下信息：
   1. 客户端支持的 SSL/TLS 协议版本
   2. 客户端生成的 第一个**随机数（Client Random）**，用于生成 **会话秘钥**
   3. 客户端支持的加密方法列表

2. Server Hello

   服务端收到 `Client Hello` 请求后，向客户端发出响应 ` Server Hello`

   主要内容如下：

   1. 确认的 SSL/TLS 协议版本，如果浏览器不支持，则关闭加密通信
   2. 服务端生成的 第二个 **随机数（Server Random）**，用于生成 **会话秘钥**
   3. 确认的加密方法列表
   4. 服务器的数字证书

3. 客户端回应

   客户端接收到 `Server Hello` 之后，首先通过 CA 公钥，确认数字证书的真实性；如果数字证书确认无疑，客户端会从数字证书中获得服务器公钥，用于加密以下报文

   1. 第三个 **随机数（pre-master key）**，依旧用于生成 **会话秘钥**
   2. **加密通信算法改变通知**，这次之后客户端发起的通信都是使用 **会话秘钥** 对称加密的
   3. **客户端握手结束通知**，以及之前所有内容的发生的数据做个摘要，供服务端校验

   **三个随机数**，使用双方商定的**加密算法**，**各自生成** 之后通信用的 **会话秘钥**

4. 服务端最后的回应

   服务器端收到客户端回应的密文，使用 **私钥** 解密，得知第三个随机数，使用加密算法，算出 **会话秘钥**，然后向客户端发送最后信息：

   1. **加密通信算法改变通知**，表示之后的响应信息都是使用 **会话秘钥** 对称加密的
   2. **服务器握手结束通知**，以及之前所有内容的发生的数据做个摘要，供客户端校验

至此，SSL/TLS 握手阶段结束。接下来的通信都是使用 **会话秘钥** 进行加密的



#### HTTP/1.1 相比 HTTP/1.0 性能上的改进

- TCP 长连接 改善了 短连接的时候，TCP连接频繁断开重连造成的性能开销
- TCP 长连接使得管道网络传输得以实现，第一个请求发出，不必等待响应就可以发出第二个请求，一定程度上减少了整体的响应时间



#### HTTP/1.1 的性能瓶颈

- 请求/响应头部未经压缩就发送，头部信息越多，延迟越大，只能压缩 body 部分
- 每次互相发送相同的头部信息会造成额外的性能浪费
- 队头阻塞，因为服务端是按照请求顺序进行相应的，如果某个响应很慢，后面的响应都会阻塞
- 没有请求优先级控制
- 请求只能从客户端开始，服务端只能被动响应



#### HTTP/2 对 HTTP/1.1 的性能瓶颈做出了什么优化？

HTTP/2 是基于 HTTPS 的，所以 HTTP/2 的安全性是有保障的，而且HTTP/1.1之后，所有通信默认使用长连接

改进：

- 头部压缩

  如果同时发出多个请求，头部一样或者相似，HTTP/2 **会消除重复的部分**

  也就是 `HPACK` 算法：客户端和服务端同时维护一张头信息表，所有字段存入这张表中，生成一个索引号，同样字段不再发送，只发送索引号，这样速度就提高了

- 二进制格式

  HTTP/1.1 的报文是文本形式的，HTTP/2 使用 **二进制**，头信息和数据体都是二进制，统称为帧（frame）：头信息帧和数据帧。这样省略了服务端文本转二进制的过程，**增加了数据传输效率**

- 数据流

  HTTP/2 的数据包也不是按照顺序发送的了，**同一个连接 中连续的数据包，可能属于不同的请求（响应）**，因此需要对数据包做标记，指出它属于谁

  **一个请求或响应的所有数据包，统称为一个数据流（Stream）**，每个数据流都有一个唯一编号；客户端发出的数据流编号为奇数，服务端发出的为偶数

  客户端还可以 **指定数据流的优先级，高优先级先响应**

- 多路复用

  HTTP/2 可以 **在一个连接中并发多个请求或相应，不用按照顺序一一对应**

  移除了 HTTP/1.1 的串行请求，就不会有 **队头阻塞** 的问题了，降级了延迟，大幅提高了连接利用率

  举例来说，在⼀个 TCP 连接⾥，服务器收到了客户端 A 和 B 的两个请求，如果发现 A 处理过程⾮常耗时，于是就 回应 A 请求已经处理好的部分，接着回应 B 请求，完成后，再回应 A 请求剩下的部分。

- 服务器推送

  HTTP/2 在一定程度上改善了传统的 **请求—响应** 工作模式，**服务端不再只能被动响应，也可以主动向客户端发送消息**

  举例来说，在浏览器刚请求 HTML 的时候，就提前把可能会⽤到的 JS、CSS ⽂件等静态资源主动发给客户端，减 少延时的等待，也就是服务器推送（Server Push，也叫 Cache Push）



#### HTTP/2 的缺陷？HTTP/3 做了哪些优化？

HTTP/2 主要的问题在于，多个 HTTP 请求复用同一个 TCP 连接，这对于 TCP协议来说是无感的，一旦发生了丢包现象，就会触发 TCP 重传，**这样在一个 TCP 连接中的所有 HTTP 请求都必须等待这个丢了的包被重传回来**

- HTTP/1.1 中的管道网络传输会有队头阻塞的问题
- HTTP/2 多个请求复⽤⼀个TCP连接，⼀旦发⽣丢包，就会阻塞住所有的 HTTP 请求

这是 TCP 传输层的问题，**所以 HTTP/3 就把 TCP协议 改为了 UDP**

UDP 不管顺序，也不管丢包，所以不会出现 HTTP/1.1 的队头阻塞和 HTTP/2 的一个丢包全部重传问题

**UDP 是不可靠传输，但基于 UDP 的 QUIC 协议可以实现类似 TCP 的可靠性传输**

- 当某个流丢包时，只会阻塞这个流，其他流不受影响
- TLS3 升级为了 1.3 版本，头部压缩算法升级为了 `QPACK`
- HTTPS 建立连接，TCP 三次握手，TLS/1.3 三次握手。QUIC 将这六次交互合并成了 3 次，减少了交互次数

所以， QUIC 是⼀个在 UDP 之上的伪 TCP + TLS + HTTP/2 的多路复⽤的协议



### HTTP/1.1 如何优化？

------

长连接，这个是 HTTP/1.1 的默认选项，从传输层入手，减少无效的 TCP 连接断开重连，来减轻服务器的压力，减少网络传输的延迟

除此之外，还有三个方向：

- 尽量避免发送 HTTP 请求
- 必须发送 HTTP 的请求时，考虑如何减少次数
- 减少服务器的 HTTP 响应的数据大小



#### 如何避免发送 HTTP 请求？

缓存，对于一定时间内可能重复请求，并且数据在一定时间内可能不会改变的请求，就应该缓存到本地（磁盘或内存）

客户端会把第一次请求以及响应的数据保存在本地，URL 为 key，响应作为 value

后续发起相同请求时，就先在缓存中查找该请求的相应数据，找到，直接从本地读取该响应。

缓存下来的数据包含头部信息，其中会有该响应缓存的过期时间，如果发现缓存的数据是过期的，就会重新发送请求。

客户端重新发送请求时，在请求的头部信息中，有一个 `ETag`，它的值是缓存的响应中的摘要（唯一标识响应的资源），服务端收到请求之后，会把这个摘要和服务端资源的摘要进行对比：

- 如果不同，说明客户端的缓存失效了，服务端会在响应中带上最新资源
- 如果相同，说明客户端缓存依旧是最新的，那就返回 `不含 body 的 304 Not Modified 响应`



#### 如何减少 HTTP 请求次数？

- 减少重定向请求次数

  - 每一次重定向就意味着多进行一次 HTTP 请求，这无疑会降低网络的性能

  - 服务端往往不止有一台服务器，比如源服务器上一级是代理服务器，与客户端直接通信的是代理服务器，那每次 请求-响应，都会重复两遍，如下

    1. 客户端 —> 代理服务器，发送 `/url1` 请求
    2. 代理服务器 —> 源服务器，发送 `/url1` 请求
    3. 源服务器 —> 代理服务器，返回 `/url1` 响应（302 Found; Location: /url2）
    4. 代理服务器 —> 客户端，返回 `/url1` 响应（302 Found; Location: /url2）
    5. 客户端 —> 代理服务器，发送 `/url2` 请求
    6. 代理服务器 —> 源服务器，发送 `/url2` 请求
    7. 源服务器 —> 代理服务器，返回 `/url2` 响应（200 OK; 资源）
    8. 代理服务器 —> 客户端，返回 `/url1` 响应（200 OK; 资源）

    **如果能让 代理服务器 完成重定向的工作，那就能减少 HTTP 请求的次数**

    1. 客户端 —> 代理服务器，发送 `/url1` 请求
    2. 代理服务器 —> 源服务器，发送 `/url1` 请求
    3. 源服务器 —> 代理服务器，返回 `/url1` 响应（302 Found; Location: /url2）
    4. 代理服务器 —> 源服务器，发送 `/url2` 请求
    5. 源服务器 —> 代理服务器，返回 `/url2` 响应（200 OK; 资源）
    6. 代理服务器 —> 客户端，返回 `/url1` 响应（200 OK; 资源）

    **再进一步，如果 代理服务器 不用与 源服务器 沟通，就能知道这个请求要重定向，直接请求重定向 URL，那又减少了 HTTP 请求的次数**

    1. 客户端 —> 代理服务器，发送 `/url1` 请求
    2. 代理服务器 —> 源服务器，发送 `/url2` 请求
    3. 源服务器 —> 代理服务器，返回 `/url2` 响应（200 OK; 资源）
    4. 代理服务器 —> 客户端，返回 `/url1` 响应（200 OK; 资源）

- 合并请求

  如果把多个小数据量的请求合并为一个请求，虽然传输资源总量不变，但是请求次数减少，就等同于 **减少了重复发送的 HTTP 头部（目的等同于 HTTP/2 的头部压缩）**

  除此之外，**合并请求也能预防队头阻塞的问题**

  合并请求有以下几种方法：

  1. `CSS Image Sprites` 把多个小图片、小图标合并为一个大图片，一次性请求返回，然后再根据 CSS 数据把大图片切割成多张小图片（减少了 HTTP 请求次数）
  2. 服务端使用 `webpack` 等打包工具把 `JS/CSS` 等资源打包成大文件（减少了 HTTP 请求次数）
  3. 还可以把图片的二进制数据用 `base64` 编码后，以 URL 的形式嵌入到 HTML 文件，跟随 HTML 文件一起发送（这样客户端收到 HTML 后，就可以直接解码出数据，然后直接显示图⽚，就不⽤再发起图⽚相关的请求，这样便减少了请求的次数）

  合并请求就是为了合并资源，以一个大资源的请求替换多个小资源的请求

  **问题：如果其中某个小资源发生了变化，那么整体都要重新请求，这就会带来额外的性能开销**

- 延迟发送请求

  每次都请求用户看到的页面资源，当用户有查看新资源的需求的时候，在再向服务端请求新的资源，这样就做到了延迟发送请求的效果



#### 如何减少 HTTP 响应的数据大小？

- 无损压缩

  > 资源经过压缩后，信息不被破坏，还能完全恢复到压缩前的原样

  适合文本文件、程序可执行文件、程序源代码

  常见的有：gzip，deflate，br（效率比 gzip 高）

  `Accept-Encoding` 请求头就是客户端告诉服务端，客户端支持的压缩算法

  `content-encoding` 响应头就是服务端告诉客户端该资源使用的压缩算法

- 有损压缩

  > 主要将次要的数据舍弃，牺牲⼀些质量来减少数据量、提⾼压缩⽐；解压的数据会与原始数据不同但是⾮常接近

  常用于多媒体数据，比如音频、视频、图片

  可以通过 HTTP 请求头部中的 `Accept` 字段⾥的 `q 质量因⼦`，告诉服务器期望的资源质量

  对于图片的压缩，目前压缩比较高的是 **Google 的 WebP 格式**

  对于音视频的压缩，⾳视频主要是动态的，每个帧都有时序的关系，通常时间连续的帧之间的变化是很⼩的。

  ⽐如，⼀个在看书的视频，画⾯通常只有⼈物的⼿和书桌上的书是会有变化的，⽽其他地⽅通常都是静态的，于是 只需要在⼀个静态的关键帧，使⽤增量数据来表达后续的帧，这样便减少了很多数据，提⾼了⽹络传输的性能。对 于视频常⻅的编码格式有 H264、H265 等，⾳频常⻅的编码格式有 AAC、AC3



## TCP

------



## IP

------



## 网络综合

------

